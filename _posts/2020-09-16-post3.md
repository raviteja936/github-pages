---
layout: post
title:  "A Dumb Survey of Artificial Intelligence"
date:   2020-09-16
time_to_read:   x min
excerpt: "AI is everywhere. But how vast is the scope of AI. This is a living document that I plan to maintain as I explore this question..."
image: "/images/ai.jpeg"
---

“Artificial Intelligence” has been in use since 1956 when the phrase was coined by a group of researchers, including Allen Newell and Herbert A. Simon.
But there is no widely agreed definition for what AI is and what it isn't. A big reason is that the goals for AI have always been fluid. CMU’s Dean of the School of Computer Science Andrew Moore's description partly captures this: "Artificial intelligence is the science and engineering of making computers behave in ways that, <b>until recently</b>, we thought required human intelligence." As technology progresses what has been sci-fi becomes a reality and the goal for AI becomes a new sci-fi!

In the next few sections, I start by defining the abstract goals for AI and deep dive into a non-exhaustive survey of certain components and algorithms used in AI.   

### Components and Goals of AI

Before defining the goals, it is imperative to state a few basic terms specific to the language of AI.
<br>
<b>Agent:</b> An agent is the system for which we want to impart Artificial Intelligence. An agent is called "rational" if it always does the <i>"right thing"</i> - more on this later.
<br>
<b>Environment:</b> An agent operates in an environment taking inputs from it and trying to modify it - technically moving from one state to another.
<br>
<b>Representation:</b> This is how an agent represents the various states.  

The core goal of AI can be defined as <b>"implementing a rational agent"</b>. Note that is is important to be able to physically implement an Agent, which means the workings of the entire environment cannot be hard-coded into the Agent to produce rationality. This implies the underlying rules of the Agent have to be emergent to a certain extent.

### Agent Types

Agents can be categorized along 3 dimensions - type of rationality, state representation and ability to learn.


<h4>1. Type of Rationality</h4>
<ul>
  <li>Reflex Agents: Agents capable of only reflexive actions - I see a car braking ahead, I brake!</li>
  <li>Model Based Reflex Agents: Agents capable of reflexive actions but also maintain an internal model of the environment based on past data - I see a traffic light turn red and expect the car ahead to brake, so I brake!</li>
  <li>Goal Based Agents</li>
  <li>Utility Based Agents</li>
</ul>


<h4>2. State Representation</h4>
<ul>
  <li>Atomic</li>
  <li>Factored</li>
  <li>Structured</li>
</ul>


<h4>3. Learning</h4>
<ul>
  <li>Ignorant</li>
  <li>Learning</li>
</ul>

<h3>Environment Types</h3>
<ul>
  <li>Fully, Partially and Non-Observable</li>
  <li>Deterministic v. Stochastic</li>
  <li>Known v. Unknown</li>
  <li>Single v. Multi-Agent</li>
  <li>Episodic v. Sequential</li>
  <li>Disrete v. Continuous</li>
  <li>Static v. Dynamic</li>
</ul>
